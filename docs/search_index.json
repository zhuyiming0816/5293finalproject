[["index.html", "Prediction of Heart Attack Chapter 1 Proposal", " Prediction of Heart Attack Yiming Zhu 2023-05-01 Chapter 1 Proposal Developing a Machine Learning Model to Predict the Risk of Heart Attack Using Heart Attack Analysis &amp; Prediction Dataset Introduction: Cardiovascular diseases (CVDs) are the leading cause of mortality worldwide, accounting for 17.9 million deaths annually or 31% of all deaths globally. Early diagnosis and care of people with CVDs or those at high cardiovascular risk can significantly improve outcomes. Heart attacks and strokes, which account for four out of every five CVD fatalities, can occur before the age of 70, highlighting the importance of early detection. Therefore, this project aims to develop a machine learning model to predict the risk of heart attack using the Heart Attack Analysis &amp; Prediction Dataset. Objectives: The primary goal of this project is to predict the probability of a person having a heart attack based on their gender, age, and cholesterol level using a linear model as the baseline model, a logistic model, and a random forest model. Additionally, the results of all three models will be compared with the “HeartDisease” variable, which is the prediction of possibility of heart attack provided by the data author. Methods: The Heart Attack Analysis &amp; Prediction Dataset will be used for this project, which includes 11 variables, including age, sex, exercise-induced angina, number of major vessels, chest pain type, resting blood pressure, cholestoral, fasting blood sugar, resting electrocardiographic results, ST depression induced by exercise relative to rest, and the target variable for heart attack prediction. Three models will be developed and compared to predict the risk of heart attack, including a linear model as the baseline model, a logistic model, and a random forest model. The models will be evaluated using accuracy, sensitivity, and specificity metrics, and the best-performing model will be selected for further analysis. The developed machine learning model will provide an accurate prediction of the probability of a person having a heart attack based on their gender, age, and cholesterol level. The results will be compared with the prediction of heart attack provided by the data author to determine the model’s effectiveness in detecting heart attack risk. The project’s findings will contribute to the early detection and prevention of heart attacks, ultimately improving patient outcomes. This repo was initially generated from a bookdown template available here: https://github.com/jtr13/IMLVtemplate. Data source: https://archive.ics.uci.edu/ml/datasets/Heart+Disease (UCI) "],["eda.html", "Chapter 2 EDA", " Chapter 2 EDA Firstly, we load the data and convert all character variables to factor variables. ## Age Sex ChestPainType RestingBP Cholesterol ## Min. :28.00 F:193 ASY:496 Min. : 0.0 Min. : 0.0 ## 1st Qu.:47.00 M:725 ATA:173 1st Qu.:120.0 1st Qu.:173.2 ## Median :54.00 NAP:203 Median :130.0 Median :223.0 ## Mean :53.51 TA : 46 Mean :132.4 Mean :198.8 ## 3rd Qu.:60.00 3rd Qu.:140.0 3rd Qu.:267.0 ## Max. :77.00 Max. :200.0 Max. :603.0 ## FastingBS RestingECG MaxHR ExerciseAngina Oldpeak ## Min. :0.0000 LVH :188 Min. : 60.0 N:547 Min. :-2.6000 ## 1st Qu.:0.0000 Normal:552 1st Qu.:120.0 Y:371 1st Qu.: 0.0000 ## Median :0.0000 ST :178 Median :138.0 Median : 0.6000 ## Mean :0.2331 Mean :136.8 Mean : 0.8874 ## 3rd Qu.:0.0000 3rd Qu.:156.0 3rd Qu.: 1.5000 ## Max. :1.0000 Max. :202.0 Max. : 6.2000 ## ST_Slope HeartDisease ## Down: 63 Min. :0.0000 ## Flat:460 1st Qu.:0.0000 ## Up :395 Median :1.0000 ## Mean :0.5534 ## 3rd Qu.:1.0000 ## Max. :1.0000 ## Age Sex ChestPainType RestingBP Cholesterol FastingBS RestingECG MaxHR ## 1 40 M ATA 140 289 0 Normal 172 ## 2 49 F NAP 160 180 0 Normal 156 ## 3 37 M ATA 130 283 0 ST 98 ## 4 48 F ASY 138 214 0 Normal 108 ## 5 54 M NAP 150 195 0 Normal 122 ## ExerciseAngina Oldpeak ST_Slope HeartDisease ## 1 N 0.0 Up 0 ## 2 N 1.0 Flat 1 ## 3 N 0.0 Up 0 ## 4 Y 1.5 Flat 1 ## 5 N 0.0 Up 0 This dataset contains 12 variables that could be used to foresee the development of a potential heart condition including age, sex, whether the patient excercise, maximum heart rate achieved , Chest Pain type and so on. Here, we select the HeartDisease, a binary variable that indicates whether a person has a heart attack or not as the response variables. Here are the first five columns of the dataset. Let examine the data first, Here is te correlogram of all the numeric variables of the data. The heart disease dataset’s correlation plot displays the correlation coefficients between various pairs of variables. Age, Resting Blood Pressure, Cholesterol, Max Heart Rate, Old Peak, and Heart Disease are the variables included in the heatmap. The correlation coefficient between any two variables is shown in each cell of the heatmap. The cell’s color serves as a gauge for the degree of correlation: orange denotes a negative correlation, blue denotes a positive correlation, and white denotes no correlation. The correlation coefficient’s magnitude is represented by the color’s hue, with stronger correlations being represented by darker hues. For instance, a positive correlation between age and the presence of heart disease is indicated by the light blue color of the cell where Age and HeartDisease intersect. The cell at the intersection of cholesterol and heart disease, on the other hand, is light orange blue, indicating a negative correlation between the presence of heart disease and cholesterol levels. Based on the result, we can see that there are some correlations between variables. Hence, I decide to include the linear model, logistic models and the random forest model as candidate models. Now, let’s split the data into two parts. One is data with ‘HeartDisease’ is 1. In this part of the dataset, the patients have more chance of heart attack. The other is data with ‘HeartDisease’ is 0. In this part of the dataset, the patients have less chance of heart attack. I will exam the histogram of numeric variables in these two data set. Here is the result of the dataset with with ‘HeartDisease’ 0. Here is the result of the dataset with with ‘HeartDisease’ 1. Based on the result, we can see that for variable ‘Oldpeak’, the is a difference of their distribution in different dataset. To build and test the models, we split data with 80/20. "],["linear-model.html", "Chapter 3 Linear Model", " Chapter 3 Linear Model Linear models are commonly employed in machine learning and statistical analysis due to their simplicity. In a linear model, the relationship between variables is assumed to be linear, indicating that the dependent variable’s change is proportional to the independent variable’s change. Following this, a linear model was constructed using the training dataset, and its performance was evaluated using the test dataset. ## ## Call: ## lm(formula = HeartDisease ~ ., data = train_data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.99914 -0.14010 0.00686 0.18379 0.97993 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3.853e-01 1.690e-01 2.280 0.022905 * ## Age 3.040e-03 1.535e-03 1.980 0.048036 * ## SexM 1.568e-01 3.153e-02 4.973 8.26e-07 *** ## ChestPainTypeATA -2.369e-01 3.814e-02 -6.212 8.86e-10 *** ## ChestPainTypeNAP -2.194e-01 3.258e-02 -6.735 3.35e-11 *** ## ChestPainTypeTA -1.911e-01 5.827e-02 -3.279 0.001092 ** ## RestingBP 5.598e-05 6.975e-04 0.080 0.936057 ## Cholesterol -5.153e-04 1.246e-04 -4.136 3.95e-05 *** ## FastingBS 1.189e-01 3.071e-02 3.871 0.000118 *** ## RestingECGNormal 1.288e-02 3.302e-02 0.390 0.696690 ## RestingECGST -2.042e-03 4.067e-02 -0.050 0.959966 ## MaxHR -2.055e-04 6.014e-04 -0.342 0.732673 ## ExerciseAnginaY 1.295e-01 3.108e-02 4.168 3.45e-05 *** ## Oldpeak 5.399e-02 1.398e-02 3.861 0.000123 *** ## ST_SlopeFlat 1.565e-01 5.245e-02 2.984 0.002940 ** ## ST_SlopeUp -2.356e-01 5.834e-02 -4.037 5.98e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.3316 on 719 degrees of freedom ## Multiple R-squared: 0.5648, Adjusted R-squared: 0.5557 ## F-statistic: 62.2 on 15 and 719 DF, p-value: &lt; 2.2e-16 ## lm.prediction ## 0 1 ## 0 69 13 ## 1 6 95 ## [1] 0.8961749 The accuracy rate is 89.61749%. "],["logistic-model.html", "Chapter 4 Logistic Model", " Chapter 4 Logistic Model Logistic regression is a statistical model used for analyzing the relationship between a binary dependent variable and one or more independent variables. It predicts the probability of an event occurring based on previous data, using a logistic function to model the relationship between the independent and dependent variables. Logistic regression is widely used in various fields, including medicine, marketing, and social sciences, to predict the likelihood of an event or outcome occurring based on specific factors. Next, we built the logistic model with training dataset and examine the model’s performance with test dataset. ## ## Call: ## glm(formula = HeartDisease ~ ., family = binomial(link = &quot;logit&quot;), ## data = train_data) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.6113 -0.3876 0.1815 0.4623 2.6343 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -2.0172393 1.5730873 -1.282 0.199722 ## Age 0.0237821 0.0149542 1.590 0.111760 ## SexM 1.4089327 0.3083171 4.570 4.88e-06 *** ## ChestPainTypeATA -1.7436606 0.3570518 -4.883 1.04e-06 *** ## ChestPainTypeNAP -1.6332337 0.2891257 -5.649 1.62e-08 *** ## ChestPainTypeTA -1.5017144 0.4709041 -3.189 0.001428 ** ## RestingBP 0.0025601 0.0066686 0.384 0.701048 ## Cholesterol -0.0041877 0.0011893 -3.521 0.000430 *** ## FastingBS 1.0007113 0.3010009 3.325 0.000885 *** ## RestingECGNormal 0.1095094 0.2985768 0.367 0.713790 ## RestingECGST -0.0680890 0.3938741 -0.173 0.862754 ## MaxHR 0.0006257 0.0055325 0.113 0.909956 ## ExerciseAnginaY 0.8881765 0.2710944 3.276 0.001052 ** ## Oldpeak 0.4137062 0.1309423 3.159 0.001581 ** ## ST_SlopeFlat 1.3637780 0.4846539 2.814 0.004894 ** ## ST_SlopeUp -1.1646171 0.5053302 -2.305 0.021185 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 1010.42 on 734 degrees of freedom ## Residual deviance: 488.17 on 719 degrees of freedom ## AIC: 520.17 ## ## Number of Fisher Scoring iterations: 5 ## glm.prediction ## 0 1 ## 0 68 14 ## 1 7 94 ## [1] 0.8852459 The accuracy rate is 88.52459%. "],["random-forest-model.html", "Chapter 5 Random Forest Model", " Chapter 5 Random Forest Model Random forest is a popular machine learning algorithm used for classification, regression, and other tasks. It operates by constructing multiple decision trees during training and outputting the mode of the classes or mean prediction of the individual trees as the final prediction. Each decision tree in the forest is trained on a random subset of the training data and a random subset of the input features, making the algorithm more resistant to overfitting and improving its generalization ability. Random forest models are widely used in various domains, including finance, healthcare, and natural language processing. Next, we built the random forest model with training dataset and examine the model’s performance with test dataset. ## IncNodePurity ## Age 12.135311 ## Sex 6.025464 ## ChestPainType 22.595150 ## RestingBP 10.243862 ## Cholesterol 16.662321 ## FastingBS 4.125195 ## RestingECG 4.615653 ## MaxHR 16.826733 ## ExerciseAngina 14.002542 ## Oldpeak 17.115808 ## ST_Slope 41.904318 ## rf.prediction ## 0 1 ## 0 66 16 ## 1 5 96 ## [1] 0.8852459 The accuracy rate is 86.88525%. "],["reflections.html", "Chapter 6 Reflections", " Chapter 6 Reflections Linear models: 89.61749% Logistic Regression Model : 88.52459% Random Forest Model : 86.88525% Based on the model accuracy results provided, it appears that the linear model has the highest accuracy with 89.61749%. This suggests that the linear model may be the best fit for the data and could potentially provide the most accurate predictions. However, it’s important to consider other factors such as interpretability and complexity of the model. The logistic regression model has an accuracy of 88.52459%, which is only slightly lower than the linear model. This suggests that logistic regression may also be a good fit for the data and could be a simpler model than the linear model, which could be an advantage in some cases. The random forest model has the lowest accuracy of the three models with 86.88525%. While it may not be the best fit for this particular dataset, it’s important to note that random forest models can often be effective for more complex datasets with non-linear relationships. Overall, it’s important to consider the specific context and goals of the analysis when selecting a model. While accuracy is an important metric, it should not be the only factor considered. Other factors such as interpretability, complexity, and scalability should also be taken into account when selecting the best model for a particular problem. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
